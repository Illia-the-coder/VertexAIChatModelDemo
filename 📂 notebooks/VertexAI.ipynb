{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install virtualenv\n",
        "!virtualenv <your-env>\n",
        "!source <your-env>/bin/activate\n",
        "!<your-env>/bin/pip install google-cloud-aiplatform"
      ],
      "metadata": {
        "id": "hNFJn4sQzO0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"shapely<2.0.0\"\n",
        "!pip install google-cloud-aiplatform --upgrade"
      ],
      "metadata": {
        "id": "Fmw64KAzrfd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project='<your-project>'"
      ],
      "metadata": {
        "id": "P86dgP73uALI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth as google_auth\n",
        "google_auth.authenticate_user()\n",
        "\n",
        "import vertexai\n",
        "from vertexai.language_models import ChatModel, InputOutputTextPair\n",
        "\n",
        "vertexai.init(project=project)\n",
        "chat_model = ChatModel.from_pretrained(\"chat-bison-32k\")\n",
        "parameters = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"max_output_tokens\": 1024,\n",
        "    \"temperature\": 0.2,\n",
        "    \"top_p\": 0.8,\n",
        "    \"top_k\": 40\n",
        "}\n",
        "chat = chat_model.start_chat()"
      ],
      "metadata": {
        "id": "b1YKdNX7rnLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\"\"\"hello\"\"\", **parameters)\n",
        "print(f\"Response from Model: {response.text}\")"
      ],
      "metadata": {
        "id": "O_B3_0ol01xc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
